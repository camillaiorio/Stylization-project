{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j1dJOz3Nbq6q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in c:\\users\\lorenzo\\pycharmprojects\\visiope\\venv\\lib\\site-packages (9.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"wget\" non Š riconosciuto come comando interno o esterno,\n",
      " un programma eseguibile o un file batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 3] Impossibile trovare il percorso specificato: '/content/train'\n",
      "C:\\Users\\Lorenzo\\PycharmProjects\\Visiope\\Style_transfer\\notebook\n",
      "C:\\Users\\Lorenzo\\PycharmProjects\\Visiope\\Style_transfer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"unzip\" non Š riconosciuto come comando interno o esterno,\n",
      " un programma eseguibile o un file batch.\n",
      "\"wget\" non Š riconosciuto come comando interno o esterno,\n",
      " un programma eseguibile o un file batch.\n",
      "\"wget\" non Š riconosciuto come comando interno o esterno,\n",
      " un programma eseguibile o un file batch.\n",
      "\"wget\" non Š riconosciuto come comando interno o esterno,\n",
      " un programma eseguibile o un file batch.\n",
      "\"wget\" non Š riconosciuto come comando interno o esterno,\n",
      " un programma eseguibile o un file batch.\n",
      "\"wget\" non Š riconosciuto come comando interno o esterno,\n",
      " un programma eseguibile o un file batch.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# install pillow\n",
    "!pip install Pillow -U\n",
    "\n",
    "# download and unzip dataset o train\n",
    "!wget http://images.cocodataset.org/zips/train2014.zip\n",
    "!mkdir train\n",
    "%cd /content/train\n",
    "!unzip -qq /content/train2014.zip\n",
    "%cd ..\n",
    "\n",
    "#download model\n",
    "!wget https://web.eecs.umich.edu/~justincj/models/vgg16-00b39a1b.pth\n",
    "  \n",
    "# download helper code\n",
    "!wget https://raw.githubusercontent.com/iamRusty/fast-neural-style-pytorch/master/transformer.py\n",
    "!wget https://raw.githubusercontent.com/iamRusty/fast-neural-style-pytorch/master/utils.py\n",
    "!wget https://raw.githubusercontent.com/iamRusty/fast-neural-style-pytorch/master/vgg.py\n",
    "\n",
    "# download style image  \n",
    "!wget https://raw.githubusercontent.com/iamRusty/fast-neural-style-pytorch/master/images/mosaic.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WNaA5voD3IY8"
   },
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import vgg\n",
    "import transformer\n",
    "import utils\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lorenzo\\PycharmProjects\\Visiope\\Style_transfer\\notebook\n"
     ]
    }
   ],
   "source": [
    "cd notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KNFhkq7xFqqH"
   },
   "outputs": [],
   "source": [
    "# GLOBAL SETTINGS\n",
    "TRAIN_IMAGE_SIZE = 256\n",
    "DATASET_PATH = \"C:/Users/Lorenzo/PycharmProjects/Visiope/coco_data/train2017\"\n",
    "NUM_EPOCHS = 1\n",
    "STYLE_IMAGE_PATH = \"C:/Users/Lorenzo/PycharmProjects/Visiope/Style_transfer/images/zero_1.jpg\"\n",
    "BATCH_SIZE = 4 \n",
    "CONTENT_WEIGHT = 17\n",
    "STYLE_WEIGHT = 50\n",
    "TV_WEIGHT = 1e-6 \n",
    "ADAM_LR = 0.001\n",
    "SAVE_MODEL_PATH = \"content/\"\n",
    "SAVE_IMAGE_PATH = \"content/\"\n",
    "SAVE_MODEL_EVERY = 500 # 2,000 Images with batch size 4\n",
    "SEED = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 18454
    },
    "colab_type": "code",
    "id": "kekf55CrdZla",
    "outputId": "ad973971-1c92-4575-cd1d-1b89d530ebcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========Epoch 1/2========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                        | 0/29572 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========Iteration 1/29572========\n",
      "\tContent Loss:\t3393610.00\n",
      "\tStyle Loss:\t22919238.00\n",
      "\tTotal Loss:\t26312848.00\n",
      "Time elapsed:\t5.137748718261719 seconds\n",
      "Saved TransformerNetwork checkpoint file at content/checkpoint_0.pth\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                             | 1/29572 [00:05<43:31:03,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample tranformed image at content/sample0_0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                             | 6/29572 [00:33<45:26:33,  5.53s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 136\u001b[0m\n\u001b[0;32m    133\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(TransformerNetwork\u001b[38;5;241m.\u001b[39mstate_dict(), final_path)\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone saving final model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 136\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[26], line 84\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     81\u001b[0m batch_total_loss_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m total_loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Backprop and Weight Update\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m \u001b[43mtotal_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Save Model and Print Losses\u001b[39;00m\n",
      "File \u001b[1;32m~\\PycharmProjects\\Visiope\\venv\\Lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\Visiope\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    # Seeds\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "    # Device\n",
    "    device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Dataset and Dataloader\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(TRAIN_IMAGE_SIZE),\n",
    "        transforms.CenterCrop(TRAIN_IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda x: x.mul(255))\n",
    "    ])\n",
    "    train_dataset = datasets.ImageFolder(DATASET_PATH, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    # Load networks\n",
    "    TransformerNetwork = transformer.TransformerNetwork().to(device)\n",
    "    VGG = vgg.VGG16('content/vgg16-00b39a1b.pth').to(device)\n",
    "\n",
    "    # Get Style Features\n",
    "    imagenet_neg_mean = torch.tensor([-103.939, -116.779, -123.68], dtype=torch.float32).reshape(1,3,1,1).to(device)\n",
    "    imagenet_mean = torch.tensor([103.939, 116.779, 123.68], dtype=torch.float32).reshape(1,3,1,1).to(device)\n",
    "    style_image = utils.load_image(STYLE_IMAGE_PATH)\n",
    "    style_tensor = utils.itot(style_image).to(device)\n",
    "    style_tensor = style_tensor.add(imagenet_neg_mean)\n",
    "    B, C, H, W = style_tensor.shape\n",
    "    style_features = VGG(style_tensor.expand([BATCH_SIZE, C, H, W]))\n",
    "    style_gram = {}\n",
    "    for key, value in style_features.items():\n",
    "        style_gram[key] = utils.gram(value)\n",
    "\n",
    "    # Optimizer settings\n",
    "    optimizer = optim.Adam(TransformerNetwork.parameters(), lr=ADAM_LR)\n",
    "\n",
    "    # Loss trackers\n",
    "    content_loss_history = []\n",
    "    style_loss_history = []\n",
    "    total_loss_history = []\n",
    "    batch_content_loss_sum = 0\n",
    "    batch_style_loss_sum = 0\n",
    "    batch_total_loss_sum = 0\n",
    "\n",
    "    # Optimization/Training Loop\n",
    "    batch_count = 1\n",
    "    start_time = time.time()\n",
    "    for epoch in range (1, NUM_EPOCHS+1):\n",
    "        print(\"========Epoch {}/{}========\".format(epoch, NUM_EPOCHS+1))\n",
    "        for batch_id, (content_batch, _) in enumerate(tqdm(train_loader)):\n",
    "            # Current Batch size in case of odd batches\n",
    "            curr_batch_size = content_batch.shape[0]\n",
    "            \n",
    "            # Zero-out Gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Generate images and get features\n",
    "            content_batch = content_batch[:,[2,1,0]].to(device)\n",
    "            generated_batch = TransformerNetwork(content_batch)\n",
    "            content_features = VGG(content_batch.add(imagenet_neg_mean))\n",
    "            generated_features = VGG(generated_batch.add(imagenet_neg_mean))\n",
    "\n",
    "            # Content Loss\n",
    "            MSELoss = nn.MSELoss().to(device)\n",
    "            content_loss = CONTENT_WEIGHT * MSELoss(content_features['relu2_2'], generated_features['relu2_2'])            \n",
    "            batch_content_loss_sum += content_loss\n",
    "\n",
    "            # Style Loss\n",
    "            style_loss = 0\n",
    "            for key, value in generated_features.items():\n",
    "                s_loss = MSELoss(utils.gram(value), style_gram[key][:curr_batch_size])\n",
    "                style_loss += s_loss\n",
    "            style_loss *= STYLE_WEIGHT\n",
    "            batch_style_loss_sum += style_loss\n",
    "\n",
    "            # Total Loss\n",
    "            total_loss = content_loss + style_loss\n",
    "            batch_total_loss_sum += total_loss.item()\n",
    "\n",
    "            # Backprop and Weight Update\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Save Model and Print Losses\n",
    "            if (((batch_count-1)%SAVE_MODEL_EVERY == 0) or (batch_count==NUM_EPOCHS*len(train_loader))):\n",
    "                # Print Losses\n",
    "                print(\"========Iteration {}/{}========\".format(batch_count, NUM_EPOCHS*len(train_loader)))\n",
    "                print(\"\\tContent Loss:\\t{:.2f}\".format(batch_content_loss_sum/batch_count))\n",
    "                print(\"\\tStyle Loss:\\t{:.2f}\".format(batch_style_loss_sum/batch_count))\n",
    "                print(\"\\tTotal Loss:\\t{:.2f}\".format(batch_total_loss_sum/batch_count))\n",
    "                print(\"Time elapsed:\\t{} seconds\".format(time.time()-start_time))\n",
    "\n",
    "                # Save Model\n",
    "                checkpoint_path = SAVE_MODEL_PATH + \"checkpoint_\" + str(batch_count-1) + \".pth\"\n",
    "                torch.save(TransformerNetwork.state_dict(), checkpoint_path)\n",
    "                print(\"Saved TransformerNetwork checkpoint file at {}\".format(checkpoint_path))\n",
    "\n",
    "                # Save sample generated image\n",
    "                sample_tensor = generated_batch[0].clone().detach().unsqueeze(dim=0)\n",
    "                sample_image = utils.ttoi(sample_tensor.clone().detach())\n",
    "                sample_image_path = SAVE_IMAGE_PATH + \"sample0_\" + str(batch_count-1) + \".png\"\n",
    "                utils.saveimg(sample_image, sample_image_path)\n",
    "                utils.show(sample_image)\n",
    "                print(\"Saved sample tranformed image at {}\".format(sample_image_path))\n",
    "\n",
    "                # Save loss histories\n",
    "                content_loss_history.append(batch_total_loss_sum/batch_count)\n",
    "                style_loss_history.append(batch_style_loss_sum/batch_count)\n",
    "                total_loss_history.append(batch_total_loss_sum/batch_count)\n",
    "\n",
    "            # Iterate Batch Counter\n",
    "            batch_count+=1\n",
    "\n",
    "    stop_time = time.time()\n",
    "    # Print loss histories\n",
    "    print(\"Done Training the Transformer Network!\")\n",
    "    print(\"Training Time: {} seconds\".format(stop_time-start_time))\n",
    "    print(\"========Content Loss========\")\n",
    "    print(content_loss_history) \n",
    "    print(\"========Style Loss========\")\n",
    "    print(style_loss_history) \n",
    "    print(\"========Total Loss========\")\n",
    "    print(total_loss_history) \n",
    "\n",
    "    # Save TransformerNetwork weights\n",
    "    TransformerNetwork.eval()\n",
    "    TransformerNetwork.cpu()\n",
    "    final_path = SAVE_MODEL_PATH + \"transformer_weight.pth\"\n",
    "    print(\"Saving TransformerNetwork weights at {}\".format(final_path))\n",
    "    torch.save(TransformerNetwork.state_dict(), final_path)\n",
    "    print(\"Done saving final model\")\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RXkHpnC36VOD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Original fast-style",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
